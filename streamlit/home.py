import streamlit as st
import os
import pickle
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from utils.preparacion_datos import cargar_datos,limpiar_datos, codificar_datos_inicial, dividir_datos, estandarizar_datos, transformacion_datos
from utils.comparacion_modelos import comparar_resultados_interactivo, comparar_metricas_modelos_especificos
# from utils.modelos import evaluar_modelos_iniciales, evaluar_modelos_iniciales_estandarizados

# from utils.codigos_mostrados import (code_librerias, code_limpieza, code_limpieza2, code_evaluar_modelos, code_codificacion_rapida,
#                                         code_division_datos, code_evaluacion_modelos, code_evaluar_modelos_estandarizados
#                                      )
from utils.codigos_mostrados import *
from utils.colores import PALETA

# Configuraci√≥n inicial de la p√°gina
st.set_page_config(page_title="An√°lisis de Abandono de Clientes", layout="wide")

# T√≠tulo y presentaci√≥n
st.markdown("<h1 style='text-align: center;color: #66BB6A;'>üéì Trabajo Integrador Final - Abandono de Clientes</h1>", unsafe_allow_html=True)
st.markdown("""
üë• Integrantes:
-
-
- Evers Juan Segundo
- Kelechian Leonardo
""")


#? Cargar datos una vez
data = cargar_datos()

#! ==============================================================
#! ==============================================================

st.markdown("---")

# Introducci√≥n
st.header("‚ú® Introducci√≥n")
st.markdown("""
[Contenido introductorio del proyecto...]
""")

#! ==============================================================
#! ==============================================================
st.markdown("---")

# Cargado de librer√≠as
st.header("üì¶ Cargado de librerias")

with st.expander("Ver c√≥digo de librer√≠as", expanded=True):
    st.code(code_librerias, language='python')

st.subheader("Datos originales")
st.dataframe(data.head())

#! ==============================================================
#! ==============================================================
st.markdown("---")


# Preparaci√≥n de Datos
st.header("‚öôÔ∏è Preparaci√≥n de los Datos")
st.subheader("Limpieza de datos")
st.markdown("""
Realizamos las siguientes transformaciones:
- Conversi√≥n de TotalCharges a num√©rico
- Tratamiento de valores nulos con imputaci√≥n por mediana
""")

# Mostrar dataset antes de la limpieza
df_mod_app = data.copy()
df_mod_app['TotalCharges'] = pd.to_numeric(df_mod_app['TotalCharges'], errors='coerce')

with st.expander("Ver c√≥digo de limpieza", expanded=True):
    st.code(code_limpieza, language='python')
    st.code(f"Cantidad de filas con valor nulo en 'Total Charges': {df_mod_app['TotalCharges'].isnull().sum()}")


st.markdown("Como vemos, ahora existen 11 filas con valor nulo en esta variable. Si bien no son muchos valores, podr√≠amos eliminarlos y es posible que el resultado final no var√≠e tanto, pero, decidimos que con el prop√≥sito de mantener todos los datos originales, se realizar√° una **Imputaci√≥n por la mediana.**")

# Gr√°fico interactivo con Plotly del boxplot de TotalCharges
fig = px.box(df_mod_app, x='TotalCharges', title='Boxplot interactivo de TotalCharges',color_discrete_sequence=PALETA)
st.plotly_chart(fig, use_container_width=True)

st.markdown("Este boxplot nos ayuda a terminar de decidir si era una buena opci√≥n el uso de la mediana para la imputaci√≥n y vemos rapidamente que hay un sesgo positivo, lo que hace que la media no sea tan representativa y pierda robustez como medida de resumen.")

with st.expander("Ver c√≥digo de imputaci√≥n", expanded=True):
    st.code(code_limpieza2, language='python')
    mediana_TotalCharges = df_mod_app['TotalCharges'].median()
    df_mod_app['TotalCharges'] = df_mod_app['TotalCharges'].fillna(mediana_TotalCharges)
    st.code(f"Cantidad de filas con valor nulo en 'Total Charges': {df_mod_app['TotalCharges'].isnull().sum()}")

st.markdown("Ahora si, la variable `TotalCharges` ya se encuentra en el tipo de dato correcto y con sus valores nulos tratados.")
st.markdown("Luego, el resto de las variables del dataset no requieren ning√∫n cambio de tipo de dato, limpieza o tratamiento de outliers.")

#! ==============================================================
#! ==============================================================
st.markdown("---")


# Modelo Base
st.header("üîé B√∫squeda de Modelo Base")
st.markdown("""
Para abordar la tarea de modelado de manera eficiente, iniciamos con una fase de 'b√∫squeda de modelo base'. 
El objetivo principal aqu√≠ es probar r√°pidamente diferentes tipos de modelos (como regresi√≥n log√≠stica, modelos basados en √°rboles, etc.) con configuraciones est√°ndar. 
Esto nos ayuda a comprender qu√© familias de modelos tienen un rendimiento inicial aceptable sin invertir tiempo excesivo en la optimizaci√≥n individual de cada uno. 
Los modelos con mejor desempe√±o en esta etapa ser√°n los que consideraremos para una optimizaci√≥n m√°s profunda.
""")
st.markdown("""
Sabiendo que hay modelos que necesitan estandarizaci√≥n, dividiremos esta busqueda en dos fases:
- Comparaci√≥n r√°pida sin procesar -> Donde solo confiaremos en las m√©tricas de los modelos de √°rboles
- Comparaci√≥n con estandarizaci√≥n -> Usaremos la misma funci√≥n pero solo con los modelos sensibles a las escalas y el data set previamente estandarizado

Por ultimo, compararemos resultados.
""")            

st.subheader("üîç Fase 1 - Comparaci√≥n r√°pida sin procesar")

st.markdown("""
Creamos la funci√≥n `evaluar_modelos()` que se utilizar√° para entrenar y evaluar varios modelos de clasificaci√≥n de forma r√°pida. 
Como habiamos mencionado, el objetivo es obtener una primera idea de qu√© modelos podr√≠an funcionar mejor para el problema dado, 
utilizando configuraciones predeterminadas o ajustes iniciales b√°sicos.            
""")
with st.expander("Ver c√≥digo de la funci√≥n `evaluar_modelos()`", expanded=True):
    st.code(code_evaluar_modelos, language='python')


st.markdown("""
            Si bien la idea es probar los datos sin modificar tanto, los modelos a entrenar necesitan que estos se encuentren en un formato n√∫merico.

Por esto, realizamos una codificaci√≥n r√°pida correspondiente a cada variable, dado que tenemos muchas categ√≥ricas.
            """)
with st.expander("Ver c√≥digo de codificaci√≥n r√°pida", expanded=True):
    st.code(code_codificacion_rapida, language='python')


st.markdown("Finalmente, dividimos los datos y evaluamos los modelos iniciales.")
with st.expander("Ver c√≥digo de divisi√≥n de datos y entrenamiento inicial", expanded=True):
    st.code(code_division_datos, language='python')
    st.code(code_evaluacion_modelos, language='python')

# Cargar resultados de modelos iniciales
@st.cache_data
def cargar_resultados():
    ruta_base = os.path.dirname(__file__)  # Carpeta actual del archivo .py
    ruta_archivo = os.path.join(ruta_base,"utils","modelos_entrenados", "resultados_iniciales.pkl")
    print(f"Cargando resultados desde: {ruta_archivo}")
    with open(ruta_archivo, "rb") as f:
        return pickle.load(f)

df_resultados = cargar_resultados()
st.dataframe(df_resultados)


#! ==============================================================

st.subheader("üîç Fase 2 - Comparaci√≥n con estandarizaci√≥n")


st.markdown("Utilizamos el mismo split de datos de antes pero estandarizamos las variables num√©ricas.")
with st.expander("Ver c√≥digo de escalado", expanded=True):
    st.code(code_escalar_inicial, language='python')

st.markdown("")
st.markdown("Ajustamos la funcion `evaluar_modelos()` pero para entrenar solo los modelos que necesitan los valores estandarizados.")
with st.expander("Ver c√≥digo de `evaluar_modelos_estandarizados()` y su evaluaci√≥n", expanded=True):
    st.code(code_evaluar_modelos_estandarizados, language='python')
    st.code(code_evaluacion_modelos_estandarizados, language='python')




#Cargar resultados de modelos estandarizados
@st.cache_data
def cargar_resultados():
    ruta_base = os.path.dirname(__file__)  # Carpeta actual del archivo .py
    ruta_archivo = os.path.join(ruta_base, "utils","modelos_entrenados", "resultados_iniciales_estandarizados.pkl")
    print(f"Cargando resultados desde: {ruta_archivo}")
    with open(ruta_archivo, "rb") as f:
        return pickle.load(f)


df_resultados_std = cargar_resultados()
st.dataframe(df_resultados_std)


st.markdown("---")
st.markdown("#### üü® Comparaci√≥n de resultados")

df_todos = comparar_resultados_interactivo(df_resultados, df_resultados_std)


st.markdown("#### Conclusi√≥n")
st.markdown("""
* ‚úÖ El modelo con mejor rendimiento general fue el `SVM_rbf` estandarizado, alcanzando la mayor Balanced Accuracy entre todos los modelos comparados.
* üå≥ El modelo `lightGBM` fue el que mejor accuracy tuvo de todos los √°rboles, teniendo casi el mismo valor que el SVM. Similar, solo por apenas debajo de este, se encuentra el de `Regresi√≥n Log√≠stica`. Ambos tambien podr√≠an ser considerados como modelo final.
* ‚ö†Ô∏è El `SVM_linear` sin estandarizar puede no ser confiable, esto se debe a que luego de ser escalado, su accuracy es mucho menor, lo que nos hace pensar que en ese primer entrenamiento se vi√≥ sesgado por la escala de alguna variable.
""")

st.markdown("""
Entonces, los modelos de
- `SVM_rbf`,
- `lightGBM`,
- `Regresi√≥n Log√≠stica`

son nuestros candidatos para ser usados en el proyecto.

Para terminar de decidirnos por uno, evaluaremos las dem√°s m√©tricas calculadas, con tal de ver cual es el que mejor se ajusta a nuestro problema.
            """)

comparar_metricas_modelos_especificos(df_todos)



st.markdown("""
#### Decisi√≥n final del modelo

Luego de evaluar distintos modelos, **decidimos seleccionar el `SVM_rbf`** como el m√°s adecuado para nuestro objetivo principal: **minimizar la p√©rdida de clientes reales (churners)**. Es decir, priorizamos un **recall alto**, ya que preferimos contactar a clientes con riesgo de irse antes que dejar pasar casos reales de abandono.

Entre los modelos evaluados:

- La **regresi√≥n log√≠stica estandarizada** obtuvo el **mayor recall (0.764)** ‚Äîproporci√≥n de churners correctamente identificados‚Äî, pero con una **precisi√≥n m√°s baja (0.527)** ‚Äîde todos los casos predichos como churn, cu√°ntos realmente lo son‚Äî. Su **F1 Score** ‚Äîpromedio arm√≥nico entre precisi√≥n y recall‚Äî fue de **0.624**.

- El modelo **`SVM_rbf` estandarizado** logr√≥ un **recall muy similar (0.752)**, pero con una **mejor precisi√≥n (0.545)** y un **F1 Score superior (0.632)**. Esto indica que detecta casi los mismos casos de churn que la regresi√≥n log√≠stica, pero con **menos falsos positivos**, lo cual es clave si las acciones de retenci√≥n tienen un costo.

- Por otro lado, **`LightGBM`** present√≥ la **mayor precisi√≥n (0.569)**, pero con un **recall m√°s bajo (0.717)**. Esto implica que, si bien acierta m√°s en sus predicciones positivas, **deja pasar m√°s casos reales de churn**, lo que no se alinea con nuestra prioridad. Su F1 Score fue de **0.635**.

En resumen, el modelo **`SVM_rbf` logra un mejor equilibrio**, manteniendo un recall alto (detectamos la mayor√≠a de los que se van), sin sacrificar tanto la precisi√≥n (no sobreactuamos en exceso), y superando a la regresi√≥n log√≠stica en F1 Score. Por estos motivos, consideramos que es la mejor elecci√≥n para nuestro caso.
            """)


#! ==============================================================
st.markdown("---")
#! ==============================================================


st.header("üõ†Ô∏è Preparaci√≥n de los datos para el modelo elegido") 
st.markdown("Habiendo elegido el modelo `SVM_rbf`, es necesario realizar una preparaci√≥n de datos m√°s detallada. Esto implica un manejo cuidadoso de la redundancia en las variables categ√≥ricas, su posterior codificaci√≥n num√©rica y la estandarizaci√≥n de las caracter√≠sticas para asegurar el mejor rendimiento del modelo.")
st.subheader("Manejo de Redundancia en variables categ√≥ricas")