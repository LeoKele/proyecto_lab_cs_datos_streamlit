import streamlit as st
import os
import pickle
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from utils.modulos.preparacion_datos import cargar_datos,limpiar_datos, codificar_datos_inicial, dividir_datos, estandarizar_datos, transformacion_datos
from utils.modulos.comparacion_modelos import comparar_resultados_interactivo, comparar_metricas_modelos_especificos, mostrar_comparacion_nuevas_variables, mostrar_comparacion_optuna_vs_gridsearch
from utils.modulos.eda import *

from utils.contenido.codigos_mostrados import *
from utils.contenido.textos_mostrados import *
from utils.colores import PALETA

# Configuraci√≥n inicial de la p√°gina
st.set_page_config(page_title="An√°lisis de Abandono de Clientes", layout="centered")

# T√≠tulo y presentaci√≥n
st.markdown("<h1 style='text-align: center;color: #66BB6A;'>üéì Trabajo Integrador Final - Abandono de Clientes</h1>", unsafe_allow_html=True)
st.markdown("""
üë• Integrantes:
- Fernando Burgos
- Francisco Garcia
- Evers Juan Segundo
- Kelechian Leonardo
""")


#? Cargar datos una vez
data = cargar_datos()

#! ==============================================================
#! ==============================================================

st.markdown("---")

# Introducci√≥n
st.header("‚ú® Introducci√≥n")
st.markdown(texto_introduccion)

#! ==============================================================
#! ==============================================================
st.markdown("---")

# Cargado de librer√≠as
st.header("üì¶ Cargado de librerias")

with st.expander("Ver c√≥digo de librer√≠as", expanded=True):
    st.code(code_librerias, language='python')

st.subheader("Datos originales")
st.dataframe(data.head())

#! ==============================================================
#! ==============================================================
st.markdown("---")
st.header("üí° Identificar la problem√°tica a resolver")
st.markdown(texto_problema)

#! ==============================================================
#! ==============================================================
st.markdown("---")


# Preparaci√≥n de Datos
st.header("‚öôÔ∏è Preparaci√≥n de los Datos")
st.subheader("Limpieza de datos")
st.markdown("""
Antes de arrancar, tenemos que corroborar que los datos se encuentren limpios de forma tal que no afecten negativamente al modelo.

Luego de realizar un peque√±o an√°lisis univariado a las columnas de nuestro data set, encontramos que la columna TotalCharges era de tipo object cuando esta deber√≠a ser float. Entonces, la casteamos y encontramos tambi√©n que escond√≠a un par de valores nulos.
""")

# Mostrar dataset antes de la limpieza
df_mod_app = data.copy()
df_mod_app['TotalCharges'] = pd.to_numeric(df_mod_app['TotalCharges'], errors='coerce')

with st.expander("Ver c√≥digo de limpieza", expanded=True):
    st.code(code_limpieza, language='python')
    st.code(f"Cantidad de filas con valor nulo en 'Total Charges': {df_mod_app['TotalCharges'].isnull().sum()}")


st.markdown("Como podemos observar, existen 11 filas con valor nulo en esta variable de un total de 7043 registros (aproximadamente 0.16% del dataset). Dado que este porcentaje es m√≠nimo y no representa una p√©rdida significativa de informaci√≥n, decidimos eliminar directamente estas filas para mantener la integridad del an√°lisis.")



with st.expander("Ver c√≥digo de imputaci√≥n", expanded=True):
    st.code(code_limpieza2, language='python')
    df_mod_app = df_mod_app.dropna(subset=['TotalCharges'])
    st.code(f"Cantidad de filas despu√©s de eliminar nulos: {len(df_mod_app)}\n"
            f"Cantidad de filas eliminadas: {len(data) - len(df_mod_app)}")


st.markdown("Ahora, la variable TotalCharges ya se encuentra en el tipo de dato correcto y sin valores nulos. El resto de las variables del dataset no requieren ning√∫n cambio de tipo de dato, limpieza o tratamiento de outliers, por lo que podemos proceder con el an√°lisis.")


#? ==============================================================
st.subheader("Limpieza de datos")
st.markdown("Para una correcta visualizaci√≥n de los datos tenemos que editar las etiquetas de la variable PaymentMethod.")
with st.expander("Ver c√≥digo de limpieza de etiquetas", expanded=True):
    st.code(code_limpieza3, language='python')
    st.markdown("**Salida:**")
    st.write(f"Valores √∫nicos en 'PaymentMethod' antes: `{df_mod_app['PaymentMethod'].unique()}`")
    
    st.markdown("")
    
    st.code(code_limpieza4, language='python')
    df_mod_app['PaymentMethod'] = df_mod_app['PaymentMethod'].str.replace(' (automatic)', '', regex=False)
    st.markdown("**Salida:**")
    st.write(f"Valores √∫nicos en 'PaymentMethod' despu√©s de limpieza: `{df_mod_app['PaymentMethod'].unique()}`")

#! ==============================================================
#! ==============================================================
st.markdown("---")
st.header("üìä EDA")
st.markdown("""
En el an√°lisis exploratorio de datos buscamos analizar las caracter√≠sticas principales del dataset a trav√©s de m√©todos de visualizaci√≥n y estad√≠sticos de res√∫men. 
El objetivo es lograr comprender c√≥mo se comportan nuestros datos y descubrir patrones y posibles relaciones entre caracter√≠sticas y la tasa de churn.
            """)
df_eda_app = df_mod_app.copy()
grafico_proporcion_churn(df_eda_app)

st.subheader("Informaci√≥n demogr√°fica")
st.markdown("A continuaci√≥n analizaremos las variables de atributos demogr√°ficos (`gender`, `SeniorCitizen`, `Partner`, `Dependents`), mostrando la proporci√≥n de `Churn` para cada categor√≠a de cada atributo.")

# Para informaci√≥n demogr√°fica
demographic_columns = ['gender', 'SeniorCitizen', 'Partner', 'Dependents']
percentage_stacked_plot_plotly(df_eda_app, demographic_columns, 'Informaci√≥n Demogr√°fica')

st.markdown("""
### Conclusiones:

‚Ä¢ La proporci√≥n de `Churn` para adultos mayores es casi el doble que para aquellos que no pertenecen a esta categor√≠a.

‚Ä¢ El g√©nero no parece tener impacto en la predicci√≥n del `Churn`. Tanto hombres como mujeres tienen similar proporci√≥n de Churners.

‚Ä¢ La proporci√≥n de Churners es mayor en clientes sin pareja.

‚Ä¢ La proporci√≥n de Churners es bastante mayor en clientes sin hijos.           
            
            """)

st.subheader("Informaci√≥n Sobre la Cuenta del Cliente - Variables Categ√≥ricas")
st.markdown("De la misma manera que hicimos con los atributos demogr√°ficos, evaluaremos la proporci√≥n de Churn para cada categor√≠a de las caracter√≠sticas del cliente (`Contract`, `PaperlessBilling`, `PaymentMethod`).")

# Para informaci√≥n de cuenta
account_columns = ['Contract', 'PaperlessBilling', 'PaymentMethod']
percentage_stacked_plot_plotly(df_eda_app, account_columns, 'Informaci√≥n Sobre la Cuenta del Cliente')

st.markdown("""
### Conclusiones:

‚Ä¢ Los clientes con contratos mensuales tienen mayor proporci√≥n de `Churn` que aquellos con contratos anuales o bianuales.

‚Ä¢ En cuanto a los m√©todos de pago, aquellos clientes que optaron por un cheque electr√≥nico son bastante m√°s propensos a Churnear que los dem√°s m√©todos de pago.

‚Ä¢ Los clientes que eligieron una facturaci√≥n electr√≥nica son m√°s propensos a Churnear.         
            """)

st.subheader("Informaci√≥n Sobre la Cuenta del Cliente - Variables Num√©ricas")
st.markdown("Los siguientes boxplots comparan la distribuci√≥n de tenure (tiempo como cliente), cargos mensuales y cargos totales entre clientes que se dieron de baja y los que permanecieron. Esto nos puede dar una idea de el comportamiento de facturaci√≥n y permanencia que podr√≠an estar relacionados con la decisi√≥n de abandonar el servicio.")
account_columns_numeric = ['tenure', 'MonthlyCharges', 'TotalCharges']
boxplot_plots_plotly(df_eda_app, account_columns_numeric, 'Informaci√≥n Sobre la Cuenta del Cliente')
st.markdown("""
### Conclusiones:

‚Ä¢ En cuanto a los cargos mensuales, hay mayor acumulaci√≥n de Churnerns en valores m√°s altos.

‚Ä¢ En clientes que Churnean, hay mayor acumulaci√≥n de registros con poca antiguedad de contrato.

‚Ä¢ Aquellos clientes que Churnean, suelen tener cargos totales m√°s bajos. Esto podr√≠a producirse debido a la relaci√≥n encontrada con `tenure` (menos meses de antiguedad, menos cargos totales).        
            """)


st.header("Estad√≠sticas Descriptivas Generales")
st.markdown("**Resumen completo de medidas estad√≠sticas para variables num√©ricas**")
st.markdown("An√°lisis descriptivo que incluye medidas de tendencia central, dispersi√≥n, posici√≥n y forma para cada variable, permitiendo comprender la distribuci√≥n y caracter√≠sticas de los datos.")
account_columns_numeric = ['tenure', 'MonthlyCharges', 'TotalCharges']
calculate_statistical_measures_streamlit(df_eda_app, account_columns_numeric)

st.subheader("An√°lisis de los Resultados: ")
st.markdown("""
`TENURE` (Antiguedad en meses):

- Distribuci√≥n: Ligeramente asim√©trica hacia la derecha (curtosis: 0.24)

- Variabilidad: Muy alta (CV: 75.7%) - hay clientes muy nuevos y muy antiguos

- Curtosis negativa (-1.39): Distribuci√≥n m√°s plana que la normal, sin concentraci√≥n en el centro



`MONTHLY CHARGES` (Cargos mensuales):

- Distribuci√≥n: Ligeramente asim√©trica hacia la izquierda (curtosis: -0.22)

- Variabilidad: Moderada (CV: 46.4%)

- Interpretaci√≥n: La mediana ($70.35) es mayor que la media ($64.80), sugiere concentraci√≥n en valores altos

- Rango: De $18.25 a $118.75 - amplio espectro de planes



`TOTAL CHARGES` (Cargos totales):

- Distribuci√≥n: Fuertemente asim√©trica hacia la derecha (curtosis: 0.96)

- Variabilidad: Extremadamente alta (CV: 99.3%) - la m√°s variable de las tres

- Interpretaci√≥n: Media ($2,283) muy superior a la mediana ($1,397) - muchos valores bajos y algunos muy altos
          
            
            
            """)


st.header("Correlacion Lineal y No Lineal")
generar_matriz_correlacion(df_eda_app)
st.subheader("Conclusi√≥n: ")
st.markdown("""
- Podemos observar una relaci√≥n fuerte ente `tenure` y `TotalCharges`.

- Podemos observar una relaci√≥n moderada entre `MonthlyCharges` y `TotalCharges`.

Para avanzar sobre el an√°lisis de estas relaciones vamos a graficarlas.           
            """)
generar_scatterplots_optimizado(df_eda_app)
st.subheader("Conclusi√≥n: ")
st.markdown("""
Vemos en el primer gr√°fico la relaci√≥n entre `tenure` y `TotalCharges`. Podemos observar una relaci√≥n lineal fuerte positiva. Esto tiene sentido, ya que a medida que aumenta la antiguedad de un cliente, sus gastos totales en el servicio van a haber aumentado dado el paso del tiempo.

Por otro lado, podemos observar una relaci√≥n similar entre `MonthlyCharges` y `TotalCharges`. Tambi√©n tiene un sentido l√≥gico, ya que aquellos clientes que tienen mayores gastos mensuales, a lo largo del tiempo, tendr√°n un a√∫n mayor gasto total.         
            
            """)


#! ==============================================================
#! ==============================================================
st.markdown("---")


# Modelo Base
st.header("üîé B√∫squeda de Modelo Base")
st.markdown("""
Para abordar la tarea de modelado de manera eficiente, iniciamos con una fase de 'b√∫squeda de modelo base'. 
El objetivo principal aqu√≠ es probar r√°pidamente diferentes tipos de modelos (como regresi√≥n log√≠stica, modelos basados en √°rboles, etc.) con configuraciones est√°ndar. 
Esto nos ayuda a comprender qu√© familias de modelos tienen un rendimiento inicial aceptable sin invertir tiempo excesivo en la optimizaci√≥n individual de cada uno. 
Los modelos con mejor desempe√±o en esta etapa ser√°n los que consideraremos para una optimizaci√≥n m√°s profunda.
""")
st.markdown("""
Sabiendo que hay modelos que necesitan estandarizaci√≥n, dividiremos esta busqueda en dos fases:
- Comparaci√≥n r√°pida sin procesar -> Donde solo confiaremos en las m√©tricas de los modelos de √°rboles
- Comparaci√≥n con estandarizaci√≥n -> Usaremos la misma funci√≥n pero solo con los modelos sensibles a las escalas y el data set previamente estandarizado

Por ultimo, compararemos resultados.
""")            

st.subheader("üîç Fase 1 - Comparaci√≥n r√°pida sin procesar")

st.markdown("""
Creamos la funci√≥n `evaluar_modelos()` que se utilizar√° para entrenar y evaluar varios modelos de clasificaci√≥n de forma r√°pida. 
Como habiamos mencionado, el objetivo es obtener una primera idea de qu√© modelos podr√≠an funcionar mejor para el problema dado, 
utilizando configuraciones predeterminadas o ajustes iniciales b√°sicos.            
""")
with st.expander("Ver c√≥digo de la funci√≥n `evaluar_modelos()`", expanded=True):
    st.code(code_evaluar_modelos, language='python')


st.markdown("""
            Si bien la idea es probar los datos sin modificar tanto, los modelos a entrenar necesitan que estos se encuentren en un formato n√∫merico.

Por esto, realizamos una codificaci√≥n r√°pida correspondiente a cada variable, dado que tenemos muchas categ√≥ricas.
            """)
with st.expander("Ver c√≥digo de codificaci√≥n r√°pida", expanded=True):
    st.code(code_codificacion_rapida, language='python')


st.markdown("Finalmente, dividimos los datos y evaluamos los modelos iniciales.")
with st.expander("Ver c√≥digo de divisi√≥n de datos y entrenamiento inicial", expanded=True):
    st.code(code_division_datos, language='python')
    st.code(code_evaluacion_modelos, language='python')

# Cargar resultados de modelos iniciales
@st.cache_data
def cargar_resultados():
    ruta_base = os.path.dirname(__file__)  # Carpeta actual del archivo .py
    ruta_archivo = os.path.join(ruta_base,"utils","modelos_entrenados", "resultados_iniciales.pkl")
    print(f"Cargando resultados desde: {ruta_archivo}")
    with open(ruta_archivo, "rb") as f:
        return pickle.load(f)

df_resultados = cargar_resultados()
st.dataframe(df_resultados)


#! ==============================================================

st.subheader("üîç Fase 2 - Comparaci√≥n con estandarizaci√≥n")


st.markdown("Utilizamos el mismo split de datos de antes pero estandarizamos las variables num√©ricas.")
with st.expander("Ver c√≥digo de escalado", expanded=True):
    st.code(code_escalar_inicial, language='python')

st.markdown("")
st.markdown("Ajustamos la funcion `evaluar_modelos()` pero para entrenar solo los modelos que necesitan los valores estandarizados.")
with st.expander("Ver c√≥digo de `evaluar_modelos_estandarizados()` y su evaluaci√≥n", expanded=True):
    st.code(code_evaluar_modelos_estandarizados, language='python')
    st.code(code_evaluacion_modelos_estandarizados, language='python')




#Cargar resultados de modelos estandarizados
@st.cache_data
def cargar_resultados():
    ruta_base = os.path.dirname(__file__)  # Carpeta actual del archivo .py
    ruta_archivo = os.path.join(ruta_base, "utils","modelos_entrenados", "resultados_iniciales_estandarizados.pkl")
    print(f"Cargando resultados desde: {ruta_archivo}")
    with open(ruta_archivo, "rb") as f:
        return pickle.load(f)


df_resultados_std = cargar_resultados()
st.dataframe(df_resultados_std)


st.markdown("---")
st.markdown("#### üü® Comparaci√≥n de resultados")

df_todos = comparar_resultados_interactivo(df_resultados, df_resultados_std)


st.markdown("#### Conclusi√≥n")
st.markdown("""
* ‚úÖ El modelo con mejor rendimiento general fue el `SVM_rbf` estandarizado, alcanzando la mayor Balanced Accuracy entre todos los modelos comparados.
* üå≥ El modelo `lightGBM` fue el que mejor accuracy tuvo de todos los √°rboles, teniendo casi el mismo valor que el SVM. Similar, solo por apenas debajo de este, se encuentra el de `Regresi√≥n Log√≠stica`. Ambos tambien podr√≠an ser considerados como modelo final.
* ‚ö†Ô∏è El `SVM_linear` sin estandarizar puede no ser confiable, esto se debe a que luego de ser escalado, su accuracy es mucho menor, lo que nos hace pensar que en ese primer entrenamiento se vi√≥ sesgado por la escala de alguna variable.
""")

st.markdown("""
Entonces, los modelos de
- `SVM_rbf`,
- `lightGBM`,
- `Regresi√≥n Log√≠stica`

son nuestros candidatos para ser usados en el proyecto.

Para terminar de decidirnos por uno, evaluaremos las dem√°s m√©tricas calculadas, con tal de ver cual es el que mejor se ajusta a nuestro problema.
            """)

comparar_metricas_modelos_especificos(df_todos)



st.markdown("""
#### Decisi√≥n final del modelo

Luego de evaluar distintos modelos, **decidimos seleccionar el `SVM_rbf`** como el m√°s adecuado para nuestro objetivo principal: **minimizar la p√©rdida de clientes reales (churners)**. Es decir, priorizamos un **recall alto**, ya que preferimos contactar a clientes con riesgo de irse antes que dejar pasar casos reales de abandono.

Entre los modelos evaluados:

- La **regresi√≥n log√≠stica estandarizada** obtuvo el **mayor recall (0.764)** ‚Äîproporci√≥n de churners correctamente identificados‚Äî, pero con una **precisi√≥n m√°s baja (0.527)** ‚Äîde todos los casos predichos como churn, cu√°ntos realmente lo son‚Äî. Su **F1 Score** ‚Äîpromedio arm√≥nico entre precisi√≥n y recall‚Äî fue de **0.624**.

- El modelo **`SVM_rbf` estandarizado** logr√≥ un **recall muy similar (0.752)**, pero con una **mejor precisi√≥n (0.545)** y un **F1 Score superior (0.632)**. Esto indica que detecta casi los mismos casos de churn que la regresi√≥n log√≠stica, pero con **menos falsos positivos**, lo cual es clave si las acciones de retenci√≥n tienen un costo.

- Por otro lado, **`LightGBM`** present√≥ la **mayor precisi√≥n (0.569)**, pero con un **recall m√°s bajo (0.717)**. Esto implica que, si bien acierta m√°s en sus predicciones positivas, **deja pasar m√°s casos reales de churn**, lo que no se alinea con nuestra prioridad. Su F1 Score fue de **0.635**.

En resumen, el modelo **`SVM_rbf` logra un mejor equilibrio**, manteniendo un recall alto (detectamos la mayor√≠a de los que se van), sin sacrificar tanto la precisi√≥n (no sobreactuamos en exceso), y superando a la regresi√≥n log√≠stica en F1 Score. Por estos motivos, consideramos que es la mejor elecci√≥n para nuestro caso.
            """)


#! ==============================================================
st.markdown("---")
#! ==============================================================


st.header("üõ†Ô∏è Preparaci√≥n de los datos para el modelo elegido") 
st.markdown("Habiendo elegido el modelo `SVM_rbf`, es necesario realizar una preparaci√≥n de datos m√°s detallada. Esto implica un manejo cuidadoso de la redundancia en las variables categ√≥ricas, su posterior codificaci√≥n num√©rica y la estandarizaci√≥n de las caracter√≠sticas para asegurar el mejor rendimiento del modelo.")
st.subheader("Manejo de Redundancia en variables categ√≥ricas")
st.markdown("""
            
            """)

st.markdown("""
[... Explicar lo que se va a hacer con las variables categ√≥ricas, por qu√© es importante manejar la redundancia y c√≥mo se va a realizar el proceso.]
            """)

with st.expander("Ver c√≥digo de manejo de redundancia", expanded=True):
    st.code(code_manejo_redun_1, language='python')
    st.code(code_manejo_redun_2, language='python')


st.subheader("Transformaci√≥n de datos")
st.markdown("""
[Se aplica el binary encoding a las variables binarias recien modificadas...]
""")
with st.expander("Ver c√≥digo de transformaci√≥n de datos", expanded=True):
    st.code(code_transformacion_1, language='python')
    st.code(code_transformacion_2, language='python')
    st.code(code_transformacion_3, language='python')

st.markdown("Comentario sobre la transformacion:")

#? ===========

mostrar_comparacion_nuevas_variables()


    


#? ===========
st.subheader("DataFrame final")
with st.expander("Ver c√≥digo de dataframe final", expanded=True):
    st.code(code_df_final, language='python')   

st.subheader("Divisi√≥n de datos")
st.markdown("""
            Antes de aplicar cualquier transformaci√≥n, debemos dividir los datos en training y testing sets para evitar un Data Leakage.
            """)
with st.expander("Ver c√≥digo de divisi√≥n de datos", expanded=True):
    st.code(code_split, language='python')

st.subheader("Estandarizaci√≥n de datos")
st.markdown("...")
with st.expander("Ver c√≥digo de estandarizaci√≥n", expanded=True):
    st.code(code_estandarizacion, language='python')

st.markdown("Finalmente, tenemos nuestro dataset listo para ser utilizado por el modelo `SVM_rbf`.")


#! ==============================================================
st.markdown("---")
#! ==============================================================


st.header("üß† Entrenamiento del modelo")
st.markdown("Ya estamos en condiciones de optimizar el modelo elegido con el prop√≥sito de mejorar a√∫n m√°s esas m√©rticas iniciales obtenidas.")


mostrar_comparacion_optuna_vs_gridsearch()