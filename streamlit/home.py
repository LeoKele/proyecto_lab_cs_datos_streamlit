import streamlit as st

# Configuraci√≥n inicial de la p√°gina
st.set_page_config(page_title="An√°lisis de Abandono de Clientes", layout="centered")

import os
import pickle
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from utils.modulos.preparacion_datos import *
from utils.modulos.comparacion_modelos import *
from utils.modulos.eda import *
from utils.modulos.evaluacion_modelo import *

from utils.contenido.codigos_mostrados import *
from utils.contenido.textos_mostrados import *
from utils.colores import PALETA, colores_barras_binarias



# T√≠tulo y presentaci√≥n
st.markdown("<h1 style='text-align: center;'>üéì Trabajo Integrador Final - Abandono de Clientes</h1>", unsafe_allow_html=True)
st.markdown("""
üë• Integrantes:
- Fernando Burgos
- Francisco Garcia
- Evers Juan Segundo
- Kelechian Leonardo
""")


#? Cargar datos una vez
data = cargar_datos()

#! ==============================================================
#! ==============================================================

st.markdown("---")

# Introducci√≥n
st.header("‚ú® Introducci√≥n")
st.markdown(texto_introduccion)

#! ==============================================================
#! ==============================================================
st.markdown("---")

# Cargado de librer√≠as
st.header("üì¶ Cargado de librerias")

with st.expander("Ver c√≥digo de librer√≠as", expanded=True):
    st.code(code_librerias, language='python')

st.subheader("Datos originales")
st.dataframe(data.head())

#! ==============================================================
#! ==============================================================
st.markdown("---")
st.header("üí° Identificar la problem√°tica a resolver")
st.markdown(texto_problema)

#! ==============================================================
#! ==============================================================
st.markdown("---")


# Preparaci√≥n de Datos
st.header("‚öôÔ∏è Preparaci√≥n de los Datos")
st.subheader("Limpieza de datos")
st.markdown("""
Antes de arrancar, tenemos que corroborar que los datos se encuentren limpios de forma tal que no afecten negativamente al modelo.

Luego de realizar un peque√±o an√°lisis univariado a las columnas de nuestro data set, encontramos que la columna TotalCharges era de tipo object cuando esta deber√≠a ser float. Entonces, la casteamos y encontramos tambi√©n que escond√≠a un par de valores nulos.
""")

# Mostrar dataset antes de la limpieza
df_mod_app = data.copy()
df_mod_app['TotalCharges'] = pd.to_numeric(df_mod_app['TotalCharges'], errors='coerce')

with st.expander("Ver c√≥digo de limpieza", expanded=True):
    st.code(code_limpieza, language='python')
    st.code(f"Cantidad de filas con valor nulo en 'Total Charges': {df_mod_app['TotalCharges'].isnull().sum()}")


st.markdown("Como podemos observar, existen 11 filas con valor nulo en esta variable de un total de 7043 registros (aproximadamente 0.16% del dataset). Dado que este porcentaje es m√≠nimo y no representa una p√©rdida significativa de informaci√≥n, decidimos eliminar directamente estas filas para mantener la integridad del an√°lisis.")



with st.expander("Ver c√≥digo de imputaci√≥n", expanded=True):
    st.code(code_limpieza2, language='python')
    df_mod_app = df_mod_app.dropna(subset=['TotalCharges'])
    st.code(f"Cantidad de filas despu√©s de eliminar nulos: {len(df_mod_app)}\n"
            f"Cantidad de filas eliminadas: {len(data) - len(df_mod_app)}")


st.markdown("Ahora, la variable TotalCharges ya se encuentra en el tipo de dato correcto y sin valores nulos. El resto de las variables del dataset no requieren ning√∫n cambio de tipo de dato, limpieza o tratamiento de outliers, por lo que podemos proceder con el an√°lisis.")


#? ==============================================================
st.subheader("Limpieza de datos")
st.markdown("Para una correcta visualizaci√≥n de los datos tenemos que editar las etiquetas de la variable PaymentMethod.")
with st.expander("Ver c√≥digo de limpieza de etiquetas", expanded=True):
    st.code(code_limpieza3, language='python')
    st.markdown("**Salida:**")
    st.write(f"Valores √∫nicos en 'PaymentMethod' antes: `{df_mod_app['PaymentMethod'].unique()}`")
    
    st.markdown("")
    
    st.code(code_limpieza4, language='python')
    df_mod_app['PaymentMethod'] = df_mod_app['PaymentMethod'].str.replace(' (automatic)', '', regex=False)
    st.markdown("**Salida:**")
    st.write(f"Valores √∫nicos en 'PaymentMethod' despu√©s de limpieza: `{df_mod_app['PaymentMethod'].unique()}`")

#! ==============================================================
#! ==============================================================
st.markdown("---")
st.header("üìä EDA")
st.markdown("""
En el an√°lisis exploratorio de datos buscamos analizar las caracter√≠sticas principales del dataset a trav√©s de m√©todos de visualizaci√≥n y estad√≠sticos de res√∫men. 
El objetivo es lograr comprender c√≥mo se comportan nuestros datos y descubrir patrones y posibles relaciones entre caracter√≠sticas y la tasa de churn.
            """)
df_eda_app = df_mod_app.copy()
grafico_proporcion_churn(df_eda_app)

st.subheader("Informaci√≥n demogr√°fica")
st.markdown("A continuaci√≥n analizaremos las variables de atributos demogr√°ficos (`gender`, `SeniorCitizen`, `Partner`, `Dependents`), mostrando la proporci√≥n de `Churn` para cada categor√≠a de cada atributo.")

# Para informaci√≥n demogr√°fica
demographic_columns = ['gender', 'SeniorCitizen', 'Partner', 'Dependents']
percentage_stacked_plot_plotly(df_eda_app, demographic_columns, 'Informaci√≥n Demogr√°fica')

st.markdown("""
### Conclusiones:

‚Ä¢ La proporci√≥n de `Churn` para adultos mayores es casi el doble que para aquellos que no pertenecen a esta categor√≠a.

‚Ä¢ El g√©nero no parece tener impacto en la predicci√≥n del `Churn`. Tanto hombres como mujeres tienen similar proporci√≥n de Churners.

‚Ä¢ La proporci√≥n de Churners es mayor en clientes sin pareja.

‚Ä¢ La proporci√≥n de Churners es mayor en clientes sin hijos.           
            
            """)

st.subheader("Informaci√≥n Sobre la Cuenta del Cliente - Variables Categ√≥ricas")
st.markdown("De la misma manera que hicimos con los atributos demogr√°ficos, evaluaremos la proporci√≥n de Churn para cada categor√≠a de las caracter√≠sticas del cliente (`Contract`, `PaperlessBilling`, `PaymentMethod`).")

# Para informaci√≥n de cuenta
account_columns = ['Contract', 'PaperlessBilling', 'PaymentMethod']
percentage_stacked_plot_plotly(df_eda_app, account_columns, 'Informaci√≥n Sobre la Cuenta del Cliente')

st.markdown("""
### Conclusiones:

‚Ä¢ Los clientes con contratos mensuales tienen mayor proporci√≥n de `Churn` que aquellos con contratos anuales o bianuales.

‚Ä¢ En cuanto a los m√©todos de pago, aquellos clientes que optaron por un cheque electr√≥nico son bastante m√°s propensos a Churnear que los dem√°s m√©todos de pago.

‚Ä¢ Los clientes que eligieron una facturaci√≥n electr√≥nica son m√°s propensos a Churnear.         
            """)

st.subheader("Informaci√≥n Sobre la Cuenta del Cliente - Variables Num√©ricas")
st.markdown("Los siguientes boxplots comparan la distribuci√≥n de tenure (antig√ºedad como cliente), cargos mensuales y cargos totales entre clientes que se dieron de baja y los que permanecieron. Esto nos puede dar una idea de el comportamiento de facturaci√≥n y permanencia que podr√≠an estar relacionados con la decisi√≥n de abandonar el servicio.")
account_columns_numeric = ['tenure', 'MonthlyCharges', 'TotalCharges']
boxplot_plots_plotly(df_eda_app, account_columns_numeric, 'Informaci√≥n Sobre la Cuenta del Cliente')
st.markdown("""
### Conclusiones:

‚Ä¢ En clientes que Churnean, hay mayor acumulaci√≥n de registros con poca antiguedad de contrato.           

‚Ä¢ En cuanto a los cargos mensuales, hay mayor acumulaci√≥n de Churnerns en valores m√°s altos.

‚Ä¢ Aquellos clientes que Churnean, suelen tener cargos totales m√°s bajos. Esto podr√≠a producirse debido a la relaci√≥n encontrada con `tenure` (menos meses de antiguedad, menos cargos totales).        
            """)


st.header("Estad√≠sticas Descriptivas Generales")
st.markdown("**Resumen completo de medidas estad√≠sticas para variables num√©ricas**")
st.markdown("An√°lisis descriptivo que incluye medidas de tendencia central, dispersi√≥n, posici√≥n y forma para cada variable, permitiendo comprender la distribuci√≥n y caracter√≠sticas de los datos.")
account_columns_numeric = ['tenure', 'MonthlyCharges', 'TotalCharges']
calculate_statistical_measures_streamlit(df_eda_app, account_columns_numeric)

st.subheader("An√°lisis de los Resultados: ")
st.markdown("""
`TENURE` (Antiguedad en meses):

- Distribuci√≥n: Ligeramente asim√©trica hacia la derecha (skewness: 0.24)

- Variabilidad: Muy alta (CV: 75.7%) - hay clientes muy nuevos y muy antiguos

- Curtosis negativa (-1.39): Distribuci√≥n m√°s plana que la normal, sin concentraci√≥n en el centro



`MONTHLY CHARGES` (Cargos mensuales):

- Distribuci√≥n: Ligeramente asim√©trica hacia la izquierda (skewness: -0.22)

- Variabilidad: Moderada (CV: 46.4%)

- Interpretaci√≥n: La mediana (USD 70.35) es mayor que la media (USD 64.80), sugiere concentraci√≥n en valores altos

- Rango: De $18.25 a $118.75 - amplio espectro de planes



`TOTAL CHARGES` (Cargos totales):

- Distribuci√≥n: Fuertemente asim√©trica hacia la derecha (curtosis: 0.96)

- Variabilidad: Extremadamente alta (CV: 99.3%) - la m√°s variable de las tres

- Interpretaci√≥n: Media (USD 2,283) muy superior a la mediana (USD 1,397) - muchos valores bajos y algunos muy altos
          
            
            
            """)


st.header("Correlacion Lineal y No Lineal")
generar_matriz_correlacion(df_eda_app)
st.subheader("Conclusi√≥n: ")
st.markdown("""
- Podemos observar una relaci√≥n fuerte ente `tenure` y `TotalCharges`.

- Podemos observar una relaci√≥n moderada entre `MonthlyCharges` y `TotalCharges`.

Para avanzar sobre el an√°lisis de estas relaciones vamos a graficarlas.           
            """)
generar_scatterplots_optimizado(df_eda_app)
st.subheader("Conclusi√≥n: ")
st.markdown("""
Vemos en el primer gr√°fico la relaci√≥n entre `tenure` y `TotalCharges`. Podemos observar una relaci√≥n lineal fuerte positiva. Esto tiene sentido, ya que a medida que aumenta la antiguedad de un cliente, sus gastos totales en el servicio van a haber aumentado dado el paso del tiempo.

Por otro lado, podemos observar una relaci√≥n similar entre `MonthlyCharges` y `TotalCharges`. Tambi√©n tiene un sentido l√≥gico, ya que aquellos clientes que tienen mayores gastos mensuales, a lo largo del tiempo, tendr√°n un a√∫n mayor gasto total.         
            
            """)


#! ==============================================================
#! ==============================================================
st.markdown("---")


# Modelo Base
st.header("üîé B√∫squeda de Modelo Base")
st.markdown("""
Para abordar la tarea de modelado de manera eficiente, iniciamos con una fase de 'b√∫squeda de modelo base'. 
El objetivo principal aqu√≠ es probar r√°pidamente diferentes tipos de modelos (como regresi√≥n log√≠stica, modelos basados en √°rboles, etc.) con configuraciones est√°ndar. 
Esto nos ayuda a comprender qu√© familias de modelos tienen un rendimiento inicial aceptable sin invertir tiempo excesivo en la optimizaci√≥n individual de cada uno. 
Los modelos con mejor desempe√±o en esta etapa ser√°n los que consideraremos para una optimizaci√≥n m√°s profunda.
""")
st.markdown("""
Sabiendo que hay modelos que necesitan estandarizaci√≥n, dividiremos esta busqueda en dos fases:
- Comparaci√≥n r√°pida sin procesar -> Donde solo confiaremos en las m√©tricas de los modelos de √°rboles
- Comparaci√≥n con estandarizaci√≥n -> Usaremos la misma funci√≥n pero solo con los modelos sensibles a las escalas y el data set previamente estandarizado

Por ultimo, compararemos resultados.
""")            

st.subheader("üîç Fase 1 - Comparaci√≥n r√°pida sin procesar")

st.markdown("""
Creamos la funci√≥n `evaluar_modelos()` que se utilizar√° para entrenar y evaluar varios modelos de clasificaci√≥n de forma r√°pida. 
Como habiamos mencionado, el objetivo es obtener una primera idea de qu√© modelos podr√≠an funcionar mejor para el problema dado, 
utilizando configuraciones predeterminadas o ajustes iniciales b√°sicos.            
""")
with st.expander("Ver c√≥digo de la funci√≥n `evaluar_modelos()`", expanded=True):
    st.code(code_evaluar_modelos, language='python')


st.markdown("""
            Si bien la idea es probar los datos sin modificar tanto, los modelos a entrenar necesitan que estos se encuentren en un formato n√∫merico.

Por esto, realizamos una codificaci√≥n r√°pida correspondiente a cada variable, dado que tenemos muchas categ√≥ricas.
            """)
with st.expander("Ver c√≥digo de codificaci√≥n r√°pida", expanded=True):
    st.code(code_codificacion_rapida, language='python')


st.markdown("Finalmente, dividimos los datos y evaluamos los modelos iniciales.")
with st.expander("Ver c√≥digo de divisi√≥n de datos y entrenamiento inicial", expanded=True):
    st.code(code_division_datos, language='python')
    st.code(code_evaluacion_modelos, language='python')

# Cargar resultados de modelos iniciales
@st.cache_data
def cargar_resultados():
    ruta_base = os.path.dirname(__file__)  # Carpeta actual del archivo .py
    ruta_archivo = os.path.join(ruta_base,"utils","modelos_entrenados", "resultados_iniciales.pkl")
    print(f"Cargando resultados desde: {ruta_archivo}")
    with open(ruta_archivo, "rb") as f:
        return pickle.load(f)

df_resultados = cargar_resultados()
st.dataframe(df_resultados)


#! ==============================================================

st.subheader("üîç Fase 2 - Comparaci√≥n con estandarizaci√≥n")


st.markdown("Utilizamos el mismo split de datos de antes pero estandarizamos las variables num√©ricas.")
with st.expander("Ver c√≥digo de escalado", expanded=True):
    st.code(code_escalar_inicial, language='python')

st.markdown("")
st.markdown("Ajustamos la funcion `evaluar_modelos()` pero para entrenar solo los modelos que necesitan los valores estandarizados.")
with st.expander("Ver c√≥digo de `evaluar_modelos_estandarizados()` y su evaluaci√≥n", expanded=True):
    st.code(code_evaluar_modelos_estandarizados, language='python')
    st.code(code_evaluacion_modelos_estandarizados, language='python')




#Cargar resultados de modelos estandarizados
@st.cache_data
def cargar_resultados():
    ruta_base = os.path.dirname(__file__)  # Carpeta actual del archivo .py
    ruta_archivo = os.path.join(ruta_base, "utils","modelos_entrenados", "resultados_iniciales_estandarizados.pkl")
    print(f"Cargando resultados desde: {ruta_archivo}")
    with open(ruta_archivo, "rb") as f:
        return pickle.load(f)


df_resultados_std = cargar_resultados()
st.dataframe(df_resultados_std)


st.markdown("---")
st.markdown("#### üü® Comparaci√≥n de resultados")

df_todos = comparar_resultados_interactivo(df_resultados, df_resultados_std)


st.markdown("#### Conclusi√≥n")
st.markdown("""
* ‚úÖ El modelo con mejor rendimiento general fue el `SVM_rbf` estandarizado, alcanzando la mayor Balanced Accuracy entre todos los modelos comparados.
* üå≥ El modelo `lightGBM` fue el que mejor accuracy tuvo de todos los √°rboles, teniendo casi el mismo valor que el SVM. Similar, solo por apenas debajo de este, se encuentra el de `Regresi√≥n Log√≠stica`. Ambos tambien podr√≠an ser considerados como modelo final.
* ‚ö†Ô∏è El `SVM_linear` sin estandarizar puede no ser confiable, esto se debe a que luego de ser escalado, su accuracy es mucho menor, lo que nos hace pensar que en ese primer entrenamiento se vi√≥ sesgado por la escala de alguna variable.
""")

st.markdown("""
Entonces, los modelos:
- `SVM_rbf`,
- `lightGBM`,
- `Regresi√≥n Log√≠stica`

son nuestros candidatos para ser usados en el proyecto.

Para terminar de decidirnos por uno, evaluaremos las dem√°s m√©tricas calculadas, con tal de ver cual es el que mejor se ajusta a nuestro problema.
            """)

comparar_metricas_modelos_especificos(df_todos)



st.markdown("""
#### Decisi√≥n final del modelo

Luego de evaluar distintos modelos, **decidimos seleccionar el `SVM_rbf`** como el m√°s adecuado para nuestro objetivo principal: **minimizar la p√©rdida de clientes reales (churners)**. Es decir, priorizamos un **recall alto**, ya que preferimos contactar a clientes con riesgo de irse antes que dejar pasar casos reales de abandono.

Entre los modelos evaluados:

- La **`Regresi√≥n Log√≠stica` estandarizada** obtuvo el **mayor recall (0.764)** ‚Äîproporci√≥n de churners correctamente identificados‚Äî, pero con una **precisi√≥n m√°s baja (0.527)** ‚Äîde todos los casos predichos como churn, cu√°ntos realmente lo son‚Äî. Su **F1 Score** ‚Äîpromedio arm√≥nico entre precisi√≥n y recall‚Äî fue de **0.624**.

- El modelo **`SVM_rbf` estandarizado** logr√≥ un **recall muy similar (0.752)**, pero con una **mejor precisi√≥n (0.545)** y un **F1 Score superior (0.632)**. Esto indica que detecta casi los mismos casos de churn que la regresi√≥n log√≠stica, pero con **menos falsos positivos**, lo cual es clave si las acciones de retenci√≥n tienen un costo.

- Por otro lado, **`LightGBM`** present√≥ la **mayor precisi√≥n (0.569)**, pero con un **recall m√°s bajo (0.717)**. Esto implica que, si bien acierta m√°s en sus predicciones positivas, **deja pasar m√°s casos reales de churn**, lo que no se alinea con nuestra prioridad. Su F1 Score fue de **0.635**.

En resumen, el modelo **`SVM_rbf` logra un mejor equilibrio**, manteniendo un recall alto (detectamos la mayor√≠a de los que se van), sin sacrificar tanto la precisi√≥n (no sobreactuamos en exceso), y superando a la regresi√≥n log√≠stica en F1 Score. Por estos motivos, consideramos que es la mejor elecci√≥n para nuestro caso.
            """)


#! ==============================================================
st.markdown("---")
#! ==============================================================


st.header("üõ†Ô∏è Preparaci√≥n de los datos para el modelo elegido") 
st.markdown("Habiendo elegido el modelo `SVM_rbf`, es necesario realizar una preparaci√≥n de datos m√°s detallada. Esto implica un manejo cuidadoso de la redundancia en las variables categ√≥ricas, su posterior codificaci√≥n num√©rica y la estandarizaci√≥n de las caracter√≠sticas para asegurar el mejor rendimiento del modelo.")
st.subheader("Manejo de Redundancia en variables categ√≥ricas")
st.markdown("""
            
            """)

st.markdown("""
A la hora de utilizar un modelo basado en SVM, menos es m√°s: un conjunto de variables bien elegidas, no redundantes y bien escaladas, permite encontrar un hiperplano m√°s limpio, m√°s generalizable y m√°s eficiente computacionalmente. Tratar la redundancia mejora tanto el rendimiento como la robustez del modelo.
            
Se reconoci√≥ que un cliente no puede tener m√∫ltiples l√≠neas si no tiene servicio telef√≥nico. Por ello, se cre√≥ una nueva variable binaria HasMultipleLines que toma el valor 1 solo si el cliente tiene servicio telef√≥nico y m√∫ltiples l√≠neas. Luego se elimin√≥ la variable original MultipleLines, eliminando as√≠ la redundancia.
            
Se observ√≥ que servicios como OnlineSecurity, StreamingTV o TechSupport solo pueden contratarse si el cliente tiene servicio de internet. Para resolver esta dependencia l√≥gica, se crearon variables binarias (HasOnlineSecurity, HasStreamingTV, etc.) que indican si el cliente tiene el servicio y adem√°s tiene internet. Las variables originales fueron eliminadas, conservando √∫nicamente la informaci√≥n relevante y no redundante.
            """)

with st.expander("Ver c√≥digo de manejo de redundancia", expanded=True):
    st.code(code_manejo_redun_1, language='python')
    st.code(code_manejo_redun_2, language='python')


st.subheader("Transformaci√≥n de datos")
st.markdown("""
Aplicamos binary encoding a las variables reci√©n creadas y luego las transformamos de booleano a num√©rico.
""")
with st.expander("Ver c√≥digo de transformaci√≥n de datos", expanded=True):
    st.code(code_transformacion_1, language='python')
    st.code(code_transformacion_2, language='python')
    st.code(code_transformacion_3, language='python')

st.markdown("")

#? ===========

mostrar_comparacion_nuevas_variables()


    


#? ===========
st.subheader("DataFrame final")
with st.expander("Ver c√≥digo de dataframe final", expanded=True):
    st.code(code_df_final, language='python')   

st.subheader("Divisi√≥n de datos")
st.markdown("""
            Antes de aplicar cualquier transformaci√≥n, debemos dividir los datos en training y testing sets para evitar un Data Leakage.
            """)
with st.expander("Ver c√≥digo de divisi√≥n de datos", expanded=True):
    st.code(code_split, language='python')

st.subheader("Estandarizaci√≥n de datos")
st.markdown("...")
with st.expander("Ver c√≥digo de estandarizaci√≥n", expanded=True):
    st.code(code_estandarizacion, language='python')

st.markdown("Finalmente, tenemos nuestro dataset listo para ser utilizado por el modelo `SVM_rbf`.")


#! ==============================================================
st.markdown("Se aplic√≥ un proceso de escalado o estandarizaci√≥n sobre las variables num√©ricas `tenure`, `MonthlyCharges` y `TotalCharges`, utilizando la t√©cnica de StandardScaler. Esta transformaci√≥n consiste en restar la media y dividir por la desviaci√≥n est√°ndar de cada variable, lo que da como resultado nuevas variables con media 0 y desviaci√≥n est√°ndar 1.")
#! ==============================================================


st.header("üß† Entrenamiento del modelo")
st.markdown("Ya estamos en condiciones de optimizar el modelo elegido con el prop√≥sito de mejorar a√∫n m√°s esas m√©tricas iniciales obtenidas.")

st.markdown("Hacemos una funci√≥n donde vamos a guardar los mejores hiperpar√°metros de cada entrenamiento para luego comparar todo junto.")
with st.expander("Ver c√≥digo funci√≥n para el DataFrame de resultados", expanded=True):
    st.code(code_resultados_busquedas, language='python')
    st.write("Creamos el DataFrame donde guardaremos estos resultados:")
    st.code("df_resultados_optimizacion = pd.DataFrame()",language='python')

st.subheader("GridSearchCV() - Hiperpar√°metros b√°sicos")
st.markdown("Se realiza una b√∫squeda de hiperpar√°metros utilizando un grid b√°sico con valores com√∫nmente utilizados. Este grid permite obtener una primera aproximaci√≥n al rendimiento del modelo sin requerir mucho tiempo de c√≥mputo. Sirve como punto de partida para identificar si existe una mejora del modelo inicial.")
with st.expander("Ver c√≥digo funci√≥n para el GridSearchCV B√°sico", expanded=True):
    st.code(code_gridSearchBasico,language='python')
    st.write("Agregamos los resultados al DF para luego comparar:")
    st.code("df_resultados_optimizacion = agregar_resultado_busqueda(df_resultados_optimizacion,grid_basico,'GridSearch - Basico')",language='python')

st.subheader("GridSearchCV() - Hiperpar√°metros Fino")
st.markdown("""
En base a los resultados obtenidos con el grid b√°sico, se define un grid m√°s fino con valores logar√≠tmicamente espaciados para los hiperpar√°metros `C` y `gamma`. Esta estrategia permite explorar con mayor detalle combinaciones en una regi√≥n m√°s amplia, incrementando la probabilidad de encontrar un mejor conjunto de hiperpar√°metros.  
            """)
with st.expander("Ver c√≥digo funci√≥n para el GridSearchCV Fino", expanded=True):
    st.code(code_gridSearchFino,language='python')
    st.write("Agregamos los resultados al DF para luego comparar:")
    st.code("df_resultados_optimizacion = agregar_resultado_busqueda(df_resultados_optimizacion,grid_fino,'GridSearch - Fino')",language='python')


st.subheader("GridSearchCV() - Hiperpar√°metros Fino V2")
st.markdown("""
A partir de los mejores valores encontrados en la b√∫squeda anterior, se realiza un ajuste m√°s localizado, centrado en un rango reducido alrededor del mejor `C` y `gamma`. Este enfoque permite afinar a√∫n m√°s el modelo, evaluando con mayor precisi√≥n peque√±as variaciones que podr√≠an mejorar ligeramente el rendimiento. B√°sicamente, hacemos un "zoom" entorno al mejor valor encontrado por el entrenamiento anterior.
""")
with st.expander("Ver c√≥digo funci√≥n para el GridSearchCV Fino", expanded=True):
    st.code(code_gridSearchFinoV2,language='python')
    st.write("Agregamos los resultados al DF para luego comparar:")
    st.code("df_resultados_optimizacion = agregar_resultado_busqueda(df_resultados_optimizacion,grid_fino_v2,'GridSearch - Fino V2')",language='python')


st.subheader("RandomizedSearchCV()")
st.markdown("""
Se aplica una b√∫squeda aleatoria con distribuciones continuas. Esta t√©cnica permite cubrir un espacio de b√∫squeda m√°s amplio, con menor costo computacional que un grid exhaustivo. Si bien no garantiza encontrar el mejor valor absoluto, puede descubrir combinaciones efectivas que un grid regular no contempla.
""")
with st.expander("Ver c√≥digo funci√≥n para el RandomizedSearchCV()", expanded=True):
    st.code(code_randomizedSearch,language='python')
    st.write("Agregamos los resultados al DF para luego comparar:")
    st.code("df_resultados_optimizacion = agregar_resultado_busqueda(df_resultados_optimizacion,random_search,'Random Search')",language='python')

st.subheader("Comparaci√≥n de las m√©tricas obtenidas en cada entrenamiento")
st.markdown("En la siguiente tabla se resumen los resultados de distintas estrategias de b√∫squeda de hiperpar√°metros aplicadas al modelo SVM, evaluadas mediante la m√©trica de Balanced Accuracy, que resulta adecuada dado el desbalance de clases presente en el dataset:")

#Cargar resultados de modelos optimizados
@st.cache_data
def cargar_resultados_optimizacion():
    ruta_base = os.path.dirname(__file__)  # Carpeta actual del archivo .py
    ruta_archivo = os.path.join(ruta_base, "utils","modelos_entrenados", "df_optimizacion.pkl")
    print(f"Cargando resultados desde: {ruta_archivo}")
    with open(ruta_archivo, "rb") as f:
        return pickle.load(f)

df_optimizacion = cargar_resultados_optimizacion()
st.dataframe(df_optimizacion)
comparacion_modelos_optimizados(df_optimizacion)

st.markdown("""Como se puede observar, el mejor rendimiento se obtuvo con la versi√≥n ajustada del Grid Search fino (V2), alcanzando una balanced accuracy del 76.56%. Esto demuestra que realizar una b√∫squeda m√°s espec√≠fica en torno a los valores √≥ptimos mejora el desempe√±o del modelo.

Tambi√©n se observa que Random Search present√≥ un rendimiento inferior al de las variantes de Grid Search, lo cual refuerza la idea de que una exploraci√≥n sistem√°tica del espacio de hiperpar√°metros, aunque m√°s costosa, puede generar mejores resultados.

En todos los casos se mantuvo el `class_weight='balanced'`, lo que permiti√≥ compensar la desproporci√≥n entre clases durante el entrenamiento.""")

df_final_app = data.copy()
modelo_comparacion = cargar_modelo_optimizado()
mostrar_comparacion_optuna_vs_gridsearch(modelo_comparacion,df_final_app)

#! ==============================================================
st.markdown("---")
#! ==============================================================


st.header("üîÆ Predicci√≥n y Evaluaci√≥n del modelo")
st.markdown("""
En esta secci√≥n vamos a mostrar el resultado final luego de entrenar nuestro modelo optimizado de `SVM` analizando todas sus m√©tricas resultantes y comparando si hubo una mejora, o no, respecto al primer entrenamiento hecho.        
            """)

st.subheader("Predicci√≥n y evaluaci√≥n del modelo")

modelo_final = cargar_modelo_optimizado().best_estimator_

mostrar_matriz_confusion(df_final_app, modelo_final)
st.markdown("### Conclusi√≥n sobre el modelo final")
st.markdown(texto_conclusion_modelo_final)

st.subheader("Importancia de predictores")


#Cargar resultados de la importancia de predictores
@st.cache_data
def cargar_resultados_importancia():
    ruta_base = os.path.dirname(__file__)  # Carpeta actual del archivo .py
    ruta_archivo = os.path.join(ruta_base, "utils","modelos_entrenados", "importancia_permutacion.pkl")
    print(f"Cargando resultados desde: {ruta_archivo}")
    with open(ruta_archivo, "rb") as f:
        return pickle.load(f)
st.write("Importancia de caracter√≠sticas por permutaci√≥n:")

df_importancia = cargar_resultados_importancia()
st.dataframe(df_importancia)

graficar_importancia_plotly(df_importancia)

st.markdown("### Variables m√°s importantes")
st.markdown(texto_variables_mas_importantes)

#! ==============================================================
st.markdown("---")
#! ==============================================================
st.header("‚úÖ Conclusi√≥n Final")
